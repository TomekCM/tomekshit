import os
import json
import time
import logging
import random
import requests
import re
from datetime import datetime
from dotenv import load_dotenv
from telegram import Update, BotCommand, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, CallbackQueryHandler
from telegram.error import TelegramError
from bs4 import BeautifulSoup
from fake_useragent import UserAgent
from urllib.parse import quote
import aiohttp
import traceback
import asyncio
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import apify


class HTMLSession:
    def __init__(self):
        options = Options()
        options.add_argument("--headless")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        self.driver = webdriver.Chrome(
            service=Service(ChromeDriverManager().install()),
            options=options
        )

    def get(self, url, proxies=None, timeout=30):
        self.driver.get(url)
        time.sleep(3)  # –î–∞–µ–º –≤—Ä–µ–º—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ JS
        return self

    @property
    def html(self):
        return self.driver

    def close(self):
        self.driver.quit()

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.close()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format="%(asctime)s %(levelname)s %(message)s",
    level=logging.INFO,
    handlers=[
        logging.FileHandler("bot.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
DEFAULT_CHECK_INTERVAL = 600  # —Å–µ–∫—É–Ω–¥ (10 –º–∏–Ω—É—Ç)
load_dotenv()
TG_TOKEN = os.getenv("TG_TOKEN")
TWITTER_BEARER = os.getenv("TWITTER_BEARER", "")
APIFY_API_TOKEN = os.getenv("APIFY_API_TOKEN", "")

# –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤
NITTER_INSTANCES = [
    "https://nitter.privacydev.net",
    "https://nitter.poast.org",
    "https://nitter.fdn.fr",
    "https://nitter.1d4.us",
    "https://nitter.kavin.rocks",
    "https://nitter.unixfox.eu",
    "https://nitter.domain.glass"
]

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
DATA_DIR = "data"
ACCOUNTS_FILE = os.path.join(DATA_DIR, "accounts.json")
SUBSCRIBERS_FILE = os.path.join(DATA_DIR, "subscribers.json")
SETTINGS_FILE = os.path.join(DATA_DIR, "settings.json")
API_LIMITS_FILE = os.path.join(DATA_DIR, "api_limits.json")
PROXIES_FILE = os.path.join(DATA_DIR, "proxies.json")

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
os.makedirs(DATA_DIR, exist_ok=True)


# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å JSON
def load_json(path, default):
    try:
        with open(path, encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return default


def save_json(path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def save_accounts(accounts_data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª"""
    save_json(ACCOUNTS_FILE, accounts_data)


# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
def get_settings():
    return load_json(SETTINGS_FILE, {
        "check_interval": DEFAULT_CHECK_INTERVAL,
        "enabled": True,
        "use_proxies": False,
        "scraper_methods": ["api", "apify", "web", "nitter"] if APIFY_API_TOKEN else ["api", "web", "nitter"],
        "max_retries": 3,
        "cache_expiry": 3600,
        "randomize_intervals": True,
        "min_interval_factor": 0.8,
        "max_interval_factor": 1.2,
        "parallel_checks": 3,
        "nitter_instances": NITTER_INSTANCES
    })


def update_setting(key, value):
    settings = get_settings()
    settings[key] = value
    save_json(SETTINGS_FILE, settings)
    return settings


# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∫—Å–∏
def get_proxies():
    return load_json(PROXIES_FILE, {"proxies": []})


def get_random_proxy():
    proxies_data = get_proxies()
    proxy_list = proxies_data.get("proxies", [])

    if not proxy_list:
        return None

    proxy = random.choice(proxy_list)
    if proxy.startswith("http"):
        return {"http": proxy, "https": proxy}
    else:
        return {"http": f"http://{proxy}", "https": f"http://{proxy}"}


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤
def init_accounts():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–ª–∏ –º–∏–≥—Ä–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç–æ–≤"""
    try:
        if not os.path.exists(ACCOUNTS_FILE):
            save_json(ACCOUNTS_FILE, {})
            return {}

        accounts = load_json(ACCOUNTS_FILE, {})

        if isinstance(accounts, list):
            logger.info("–ú–∏–≥—Ä–∏—Ä—É–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ –≤ —Å–ª–æ–≤–∞—Ä—å")
            new_accounts = {}
            for account in accounts:
                username = account.get("username", "")
                if username:
                    new_accounts[username.lower()] = {
                        "username": username,
                        "added_at": account.get("added_at", datetime.now().isoformat()),
                        "last_check": account.get("last_check"),
                        "last_tweet_id": None,
                        "check_count": 0,
                        "success_rate": 100.0,
                        "fail_count": 0,
                        "check_method": None,
                        "priority": 1.0,
                        "first_check": True
                    }
            save_json(ACCOUNTS_FILE, new_accounts)
            return new_accounts

        updated = False
        for username, account in accounts.items():
            if "check_count" not in account:
                account["check_count"] = 0
                updated = True
            if "success_rate" not in account:
                account["success_rate"] = 100.0
                updated = True
            if "fail_count" not in account:
                account["fail_count"] = 0
                updated = True
            if "check_method" not in account:
                account["check_method"] = None
                updated = True
            if "priority" not in account:
                account["priority"] = 1.0
                updated = True
            if "first_check" not in account:
                account["first_check"] = True
                updated = True

        if updated:
            save_json(ACCOUNTS_FILE, accounts)

        return accounts
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {e}")
        save_json(ACCOUNTS_FILE, {})
        return {}


async def check_instance(session, instance):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–∞"""
    try:
        async with session.get(
                f"{instance}/twitter",
                timeout=10,
                headers={"User-Agent": "Mozilla/5.0"}
        ) as response:
            return response.status == 200
    except:
        return False


async def update_nitter_instances():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–∞–±–æ—á–∏—Ö Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤"""
    working_instances = []

    async with aiohttp.ClientSession() as session:
        tasks = []
        for instance in NITTER_INSTANCES:
            tasks.append(check_instance(session, instance))

        results = await asyncio.gather(*tasks, return_exceptions=True)

        for instance, is_working in zip(NITTER_INSTANCES, results):
            if is_working and not isinstance(is_working, Exception):
                working_instances.append(instance)
                logger.info(f"Nitter instance available: {instance}")

    settings = get_settings()
    settings["nitter_instances"] = working_instances
    save_json(SETTINGS_FILE, settings)

    return working_instances


# –ú–µ—Ç–æ–¥—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Twitter
class TwitterClient:
    def __init__(self, bearer_token):
        self.bearer_token = bearer_token
        self.rate_limited = False
        self.rate_limit_reset = 0
        self.user_agent = UserAgent().random
        self.cache = {}
        self.session = requests.Session()

    def clear_cache(self):
        self.cache = {}

    def update_user_agent(self):
        self.user_agent = UserAgent().random

    def check_rate_limit(self):
        if self.rate_limited:
            now = time.time()
            if now < self.rate_limit_reset:
                return False
            else:
                self.rate_limited = False
        return True

    def set_rate_limit(self, reset_time):
        self.rate_limited = True
        self.rate_limit_reset = reset_time

    def get_cache_key(self, method, identifier):
        return f"{method}:{identifier}"

    def get_cached_data(self, cache_key, max_age=3600):
        if cache_key in self.cache:
            item = self.cache[cache_key]
            if time.time() - item['timestamp'] < max_age:
                return item['data']
        return None

    def set_cache(self, cache_key, data):
        self.cache[cache_key] = {
            'data': data,
            'timestamp': time.time()
        }

    def get_user_by_username(self, username):
        if not self.bearer_token or not self.check_rate_limit():
            return None

        cache_key = self.get_cache_key("user", username.lower())
        cached = self.get_cached_data(cache_key)
        if cached:
            return cached

        url = f"https://api.twitter.com/2/users/by/username/{username}"
        headers = {
            "Authorization": f"Bearer {self.bearer_token}",
            "User-Agent": self.user_agent
        }

        try:
            response = self.session.get(url, headers=headers, timeout=10)

            if response.status_code == 429:
                reset_time = int(response.headers.get("x-rate-limit-reset", time.time() + 900))
                self.set_rate_limit(reset_time)
                remaining = int(response.headers.get("x-rate-limit-remaining", 0))
                limit = int(response.headers.get("x-rate-limit-limit", 0))
                logger.warning(
                    f"API –ª–∏–º–∏—Ç: {remaining}/{limit} –∑–∞–ø—Ä–æ—Å–æ–≤. –°–±—Ä–æ—Å –≤ {reset_time}"
                )
                return None

            if response.status_code == 200:
                data = response.json()
                if "data" in data:
                    self.set_cache(cache_key, data["data"])
                    return data["data"]
            else:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {response.status_code} - {response.text}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ API: {e}")

        return None

    def get_user_tweets(self, user_id, use_proxies=False):
        if not self.bearer_token or not self.check_rate_limit():
            return None

        cache_key = self.get_cache_key("tweets", user_id)
        cached = self.get_cached_data(cache_key, 300)
        if cached:
            return cached

        url = f"https://api.twitter.com/2/users/{user_id}/tweets"
        params = {
            "max_results": 5,
            "tweet.fields": "created_at,text",
            "exclude": "retweets,replies"
        }
        headers = {
            "Authorization": f"Bearer {self.bearer_token}",
            "User-Agent": self.user_agent
        }

        try:
            proxies = get_random_proxy() if use_proxies else None
            response = self.session.get(url, headers=headers, params=params, proxies=proxies, timeout=10)

            if response.status_code == 429:
                reset_time = int(response.headers.get("x-rate-limit-reset", time.time() + 900))
                self.set_rate_limit(reset_time)
                remaining = int(response.headers.get("x-rate-limit-remaining", 0))
                limit = int(response.headers.get("x-rate-limit-limit", 0))
                logger.warning(
                    f"API –ª–∏–º–∏—Ç —Ç–≤–∏—Ç–æ–≤: {remaining}/{limit}. –°–±—Ä–æ—Å –≤ {reset_time}"
                )
                return None

            if response.status_code == 200:
                data = response.json()
                tweets = data.get("data", [])
                self.set_cache(cache_key, tweets)
                return tweets
            else:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–≤–∏—Ç–æ–≤: {response.status_code} - {response.text}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ API: {e}")

        return None

    def get_latest_tweet(self, username, use_proxies=False):
        user = self.get_user_by_username(username)
        if not user:
            return None, None, None

        user_id = user["id"]
        tweets = self.get_user_tweets(user_id, use_proxies)

        if not tweets or len(tweets) == 0:
            return user_id, None, None

        latest = tweets[0]
        tweet_id = latest["id"]
        tweet_text = latest["text"]
        tweet_url = f"https://twitter.com/{username}/status/{tweet_id}"

        return user_id, tweet_id, {"text": tweet_text, "url": tweet_url}


# –°–∫—Ä–∞–ø–µ—Ä—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–≤–∏—Ç–æ–≤
class TwitterScrapers:
    def __init__(self):
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:96.0) Gecko/20100101 Firefox/96.0",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36"
        ]
        self.cache = {}
        self.session = requests.Session()
        self.async_session = None

    def get_random_user_agent(self):
        return random.choice(self.user_agents)

    def get_cache_key(self, method, username):
        return f"{method}:{username.lower()}"

    def get_cached_data(self, cache_key, max_age=300):
        if cache_key in self.cache:
            item = self.cache[cache_key]
            if time.time() - item['timestamp'] < max_age:
                return item['data']
        return None

    def set_cache(self, cache_key, data):
        self.cache[cache_key] = {
            'data': data,
            'timestamp': time.time()
        }

    async def init_async_session(self):
        if self.async_session is None:
            self.async_session = aiohttp.ClientSession()

    async def close_async_session(self):
        if self.async_session:
            await self.async_session.close()
            self.async_session = None

    def validate_tweet_id(self, username, tweet_id):
        if not tweet_id:
            return False
        if len(str(tweet_id)) < 15:
            logger.warning(f"–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ID —Ç–≤–∏—Ç–∞ –¥–ª—è @{username}: {tweet_id}")
            return False
        return True

    async def get_latest_tweet_apify(self, username, use_proxies=False):
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–≤–∏—Ç —á–µ—Ä–µ–∑ Apify API"""
        cache_key = self.get_cache_key("apify", username)
        cached = self.get_cached_data(cache_key)
        if cached:
            return cached

        if not APIFY_API_TOKEN:
            return None, None

        try:
            apify_client = apify.ApiClient(APIFY_API_TOKEN)

            run_input = {
                "usernames": [username],
                "maxTweets": 1,
                "proxyConfig": {"useApifyProxy": True} if use_proxies else {}
            }

            run = await apify_client.actor("quacker/twitter-scraper").call(run_input=run_input)
            items = await apify_client.dataset(run["defaultDatasetId"]).list_items()

            if items and len(items) > 0:
                tweet = items[0]
                tweet_id = tweet["id"]
                tweet_text = tweet.get("text", "[–¢–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω]")
                tweet_url = f"https://twitter.com/{username}/status/{tweet_id}"

                result = (tweet_id, {"text": tweet_text, "url": tweet_url})
                self.set_cache(cache_key, result)
                logger.info(f"–ù–∞–π–¥–µ–Ω —Ç–≤–∏—Ç ID {tweet_id} –¥–ª—è @{username} —á–µ—Ä–µ–∑ Apify")
                return result

        except Exception as e:
            logger.error(f"Apify error for @{username}: {e}")

        return None, None

    def get_latest_tweet_web(self, username, use_proxies=False):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –≤–µ–±-–ø–∞—Ä—Å–∏–Ω–≥ —Å requests-html"""
        cache_key = self.get_cache_key("web", username)
        cached = self.get_cached_data(cache_key)
        if cached:
            return cached

        try:
            session = HTMLSession()
            url = f"https://twitter.com/{username}"
            proxies = get_random_proxy() if use_proxies else None

            response = session.get(url, proxies=proxies, timeout=30)
            response.html.render(timeout=20, sleep=3)

            tweets = response.html.find('article[data-testid="tweet"]')

            if not tweets:
                tweets = response.html.find('div[data-testid="tweetText"]')

            if tweets:
                first_tweet = tweets[0]
                tweet_id = first_tweet.attrs.get("data-tweet-id")

                if not tweet_id:
                    links = first_tweet.absolute_links
                    for link in links:
                        if '/status/' in link:
                            tweet_id = link.split('/status/')[-1].split('/')[0]
                            break

                if tweet_id:
                    tweet_text = first_tweet.text
                    tweet_url = f"https://twitter.com/{username}/status/{tweet_id}"
                    result = (tweet_id, {"text": tweet_text, "url": tweet_url})
                    self.set_cache(cache_key, result)
                    logger.info(f"–ù–∞–π–¥–µ–Ω —Ç–≤–∏—Ç ID {tweet_id} –¥–ª—è @{username} —á–µ—Ä–µ–∑ –≤–µ–±-–ø–∞—Ä—Å–∏–Ω–≥")
                    return result

        except Exception as e:
            logger.error(f"Web scraping error for @{username}: {e}")

        return None, None

    def get_latest_tweet_nitter(self, username, use_proxies=False):
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–≤–∏—Ç —á–µ—Ä–µ–∑ Nitter"""
        cache_key = self.get_cache_key("nitter", username)
        cached = self.get_cached_data(cache_key)
        if cached:
            return cached

        settings = get_settings()
        nitter_instances = settings.get("nitter_instances", NITTER_INSTANCES)
        random.shuffle(nitter_instances)

        for base_url in nitter_instances[:3]:
            url = f"{base_url}/{username}"
            headers = {
                "User-Agent": self.get_random_user_agent(),
                "Accept-Language": "en-US,en;q=0.9",
                "Accept": "text/html,application/xhtml+xml,application/xml",
            }

            try:
                proxies = get_random_proxy() if use_proxies else None
                response = self.session.get(url, headers=headers, proxies=proxies, timeout=10)

                if response.status_code != 200:
                    continue

                soup = BeautifulSoup(response.text, "html.parser")
                timeline_items = soup.select(".timeline-item")

                if not timeline_items:
                    continue

                for item in timeline_items:
                    pinned_icon = item.select_one(".pinned")
                    if pinned_icon:
                        continue

                    link = item.select_one(".tweet-link")
                    if not link or "href" not in link.attrs:
                        continue

                    href = link["href"]
                    match = re.search(r'/status/(\d+)', href)
                    if not match:
                        continue

                    tweet_id = match.group(1)
                    tweet_header = item.select_one(".tweet-header")
                    if tweet_header:
                        header_text = tweet_header.get_text(strip=True).lower()
                        if "retweeted" in header_text or "—Ä–µ—Ç–≤–∏—Ç–Ω—É–ª" in header_text:
                            continue

                    content = item.select_one(".tweet-content")
                    tweet_text = content.get_text(strip=True) if content else "[–ù–æ–≤—ã–π —Ç–≤–∏—Ç]"
                    tweet_url = f"https://twitter.com/{username}/status/{tweet_id}"

                    result = (tweet_id, {"text": tweet_text, "url": tweet_url})
                    self.set_cache(cache_key, result)
                    return result

                if timeline_items:
                    item = timeline_items[0]
                    link = item.select_one(".tweet-link")
                    if link and "href" in link.attrs:
                        href = link["href"]
                        match = re.search(r'/status/(\d+)', href)
                        if match:
                            tweet_id = match.group(1)
                            content = item.select_one(".tweet-content")
                            tweet_text = content.get_text(strip=True) if content else "[–¢–≤–∏—Ç]"
                            tweet_url = f"https://twitter.com/{username}/status/{tweet_id}"

                            result = (tweet_id, {"text": tweet_text, "url": tweet_url})
                            self.set_cache(cache_key, result)
                            return result

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–≤–∏—Ç–∞ —á–µ—Ä–µ–∑ Nitter –¥–ª—è {username}: {e}")

        return None, None

    async def get_latest_tweet_multi(self, username, methods=None, use_proxies=False):
        """–ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–≤–∏—Ç —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ"""
        await self.init_async_session()

        if not methods:
            methods = ["apify", "nitter", "web"] if APIFY_API_TOKEN else ["nitter", "web"]

        tasks = []

        for method in methods:
            if method == "apify":
                tasks.append(asyncio.create_task(self.get_latest_tweet_apify(username, use_proxies)))
            elif method == "nitter":
                tasks.append(asyncio.create_task(self.get_latest_tweet_nitter_async(username, use_proxies)))
            elif method == "web":
                tasks.append(asyncio.create_task(self.get_latest_tweet_web_async(username, use_proxies)))

        done, pending = await asyncio.wait(
            tasks,
            return_when=asyncio.FIRST_COMPLETED
        )

        for task in pending:
            task.cancel()

        result = None
        for task in done:
            try:
                method_result = task.result()
                if method_result and method_result[0]:
                    result = method_result
                    break
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ –¥–ª—è {username}: {e}")

        return result

    async def get_latest_tweet_web_async(self, username, use_proxies=False):
        return self.get_latest_tweet_web(username, use_proxies)

    async def get_latest_tweet_nitter_async(self, username, use_proxies=False):
        return self.get_latest_tweet_nitter(username, use_proxies)


# –ú–Ω–æ–≥–æ–º–µ—Ç–æ–¥–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–≤–∏—Ç–æ–≤
async def check_tweet_multi_method(username, methods=None, use_proxies=False):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–≤–∏—Ç—ã –≤—Å–µ–º–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
    if not methods:
        settings = get_settings()
        methods = settings.get("scraper_methods",
                               ["api", "apify", "web", "nitter"] if APIFY_API_TOKEN else ["api", "web", "nitter"])

    twitter_api = TwitterClient(TWITTER_BEARER)
    scrapers = TwitterScrapers()

    scrapers.cache = {k: v for k, v in scrapers.cache.items() if not k.lower().endswith(username.lower())}

    user_id = None
    tweet_id = None
    tweet_data = None
    successful_method = None

    for method in methods:
        if tweet_id:
            break

        try:
            if method == "api" and TWITTER_BEARER and not twitter_api.rate_limited:
                user_id, tweet_id, tweet_data = twitter_api.get_latest_tweet(username, use_proxies)
                if tweet_id:
                    successful_method = "api"

            elif method == "apify" and APIFY_API_TOKEN:
                tweet_id, tweet_data = await scrapers.get_latest_tweet_apify(username, use_proxies)
                if tweet_id:
                    successful_method = "apify"

            elif method == "nitter":
                tweet_id, tweet_data = scrapers.get_latest_tweet_nitter(username, use_proxies)
                if tweet_id:
                    successful_method = "nitter"

            elif method == "web":
                tweet_id, tweet_data = scrapers.get_latest_tweet_web(username, use_proxies)
                if tweet_id:
                    successful_method = "web"

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {username} –º–µ—Ç–æ–¥–æ–º {method}: {e}")

    await scrapers.close_async_session()

    if tweet_id and len(str(tweet_id)) < 15:
        logger.warning(f"–ü–æ–ª—É—á–µ–Ω –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–π ID —Ç–≤–∏—Ç–∞ –¥–ª—è @{username}: {tweet_id}. –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º.")
        return user_id, None, None, None

    return user_id, tweet_id, tweet_data, successful_method


# [–û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±–æ—Ç–∞ (cmd_start, cmd_add, cmd_remove, cmd_list –∏ —Ç.–¥.) –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π]
# [–§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Ç–∞–∫–∂–µ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π]
async def on_startup(app):
    """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞"""
    global background_task

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞
    await app.bot.set_my_commands([
        BotCommand("start", "–ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã"),
        BotCommand("add", "–î–æ–±–∞–≤–∏—Ç—å –∞–∫–∫–∞—É–Ω—Ç"),
        BotCommand("remove", "–£–¥–∞–ª–∏—Ç—å –∞–∫–∫–∞—É–Ω—Ç"),
        BotCommand("list", "–°–ø–∏—Å–æ–∫ –∞–∫–∫–∞—É–Ω—Ç–æ–≤"),
        BotCommand("check", "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–≤–∏—Ç—ã"),
        BotCommand("interval", "–ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏"),
        BotCommand("settings", "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞"),
        BotCommand("proxy", "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∫—Å–∏"),
        BotCommand("stats", "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"),
        BotCommand("update_nitter", "–û–±–Ω–æ–≤–∏—Ç—å Nitter-–∏–Ω—Å—Ç–∞–Ω—Å—ã")
    ])

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    init_accounts()

    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –ø—Ä–æ–∫—Å–∏, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if not os.path.exists(PROXIES_FILE):
        save_json(PROXIES_FILE, {"proxies": []})

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤
    try:
        logger.info("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤...")
        await update_nitter_instances()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤: {e}")

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
    background_task = asyncio.create_task(background_check(app))
    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω, —Ñ–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞")

async def on_shutdown(app):
    """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –±–æ—Ç–∞"""
    global background_task
    if background_task and not background_task.cancelled():
        logger.info("–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É...")
        background_task.cancel()
        try:
            await background_task
        except asyncio.CancelledError:
            pass
        logger.info("–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≤—Å–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏
    scrapers = TwitterScrapers()
    await scrapers.close_async_session()

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏
background_task = None

async def background_check(app):
    """–§–æ–Ω–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫–∫–∞—É–Ω—Ç–æ–≤"""
    global background_task
    background_task = asyncio.current_task()

    await asyncio.sleep(10)  # –ù–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞

    while True:
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç–º–µ–Ω—É –∑–∞–¥–∞—á–∏
            if asyncio.current_task().cancelled():
                logger.info("–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                break

            settings = get_settings()
            if not settings.get("enabled", True):
                logger.info("–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Ç–∫–ª—é—á–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É")
                await asyncio.sleep(settings["check_interval"])
                continue

            logger.info("–§–æ–Ω–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫–∫–∞—É–Ω—Ç–æ–≤")
            subs = load_json(SUBSCRIBERS_FILE, [])
            accounts = init_accounts()

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É, –µ—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –∏–ª–∏ –∞–∫–∫–∞—É–Ω—Ç–æ–≤
            if not subs or not accounts:
                logger.info("–ù–µ—Ç –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –∏–ª–∏ –∞–∫–∫–∞—É–Ω—Ç–æ–≤, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É")
                await asyncio.sleep(settings["check_interval"])
                continue

            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            use_proxies = settings.get("use_proxies", False)
            methods = settings.get("scraper_methods", ["web", "nitter", "api"])
            parallel_checks = settings.get("parallel_checks", 3)
            randomize = settings.get("randomize_intervals", True)
            accounts_updated = False

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
            sorted_accounts = sorted(
                accounts.items(),
                key=lambda x: (
                    datetime.fromisoformat(x[1].get("last_check", "2000-01-01T00:00:00")),
                    -x[1].get("priority", 1.0)
                )
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã –≥—Ä—É–ø–ø–∞–º–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            for i in range(0, len(sorted_accounts), parallel_checks):
                # –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞, –≤—ã—Ö–æ–¥–∏–º
                if asyncio.current_task().cancelled():
                    logger.info("–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                    return

                # –ë–µ—Ä–µ–º –æ—á–µ—Ä–µ–¥–Ω—É—é –≥—Ä—É–ø–ø—É –∞–∫–∫–∞—É–Ω—Ç–æ–≤
                batch = sorted_accounts[i:i + parallel_checks]
                tasks = []

                # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–∫–∫–∞—É–Ω—Ç–æ–≤
                for username, account in batch:
                    if asyncio.current_task().cancelled():
                        break

                    display_name = account.get('username', username)
                    tasks.append(process_account(app, subs, accounts, display_name, account, methods, use_proxies))

                # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
                if tasks:
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    for result in results:
                        if isinstance(result, Exception):
                            logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ: {result}")
                        elif result:  # –ï—Å–ª–∏ –±—ã–ª –æ–±–Ω–æ–≤–ª–µ–Ω –∞–∫–∫–∞—É–Ω—Ç
                            accounts_updated = True

                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏
                await asyncio.sleep(3)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            if accounts_updated:
                save_accounts(accounts)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            if randomize:
                # –°–ª—É—á–∞–π–Ω–æ–µ –≤—Ä–µ–º—è –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                min_factor = settings.get("min_interval_factor", 0.8)
                max_factor = settings.get("max_interval_factor", 1.2)
                factor = random.uniform(min_factor, max_factor)
                wait_time = int(settings["check_interval"] * factor)
                logger.info(f"–°–ª—É—á–∞–π–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è: {wait_time} —Å–µ–∫—É–Ω–¥ (x{factor:.2f})")
            else:
                wait_time = settings["check_interval"]
                logger.info(f"–°–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ {wait_time} —Å–µ–∫—É–Ω–¥")

            await asyncio.sleep(wait_time)

        except asyncio.CancelledError:
            logger.info("–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
            break
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
            traceback.print_exc()
            # –ù–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–¥–∞—á—É –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
            await asyncio.sleep(60)

async def process_account(app, subs, accounts, username, account, methods, use_proxies):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –∞–∫–∫–∞—É–Ω—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø—Ä–∏ –Ω–æ–≤—ã—Ö —Ç–≤–∏—Ç–∞—Ö"""
    try:
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        account['last_check'] = datetime.now().isoformat()
        account['check_count'] = account.get('check_count', 0) + 1

        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–≤–∏—Ç –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –ø–µ—Ä–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        last_id = account.get('last_tweet_id')
        first_check = account.get('first_check', False)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º—É–ª—å—Ç–∏–º–µ—Ç–æ–¥–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
        user_id, tweet_id, tweet_data, method = await check_tweet_multi_method(
            username, methods, use_proxies
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –Ω–æ–≤—ã–π
        if user_id and not account.get('user_id'):
            account['user_id'] = user_id

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–≤–∏—Ç
        if not tweet_id:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –Ω–µ—É–¥–∞—á
            account['fail_count'] = account.get('fail_count', 0) + 1

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞
            total_checks = account.get('check_count', 1)
            fail_count = account.get('fail_count', 0)
            account['success_rate'] = 100 * (total_checks - fail_count) / total_checks

            # –£–º–µ–Ω—å—à–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤
            if account.get('fail_count', 0) > 3:
                account['priority'] = max(0.1, account.get('priority', 1.0) * 0.9)

            logger.info(f"–ê–∫–∫–∞—É–Ω—Ç @{username}: —Ç–≤–∏—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (–º–µ—Ç–æ–¥—ã: {methods})")
            return True

        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –Ω–µ—É–¥–∞—á –ø—Ä–∏ —É—Å–ø–µ—Ö–µ –∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        if account.get('fail_count', 0) > 0:
            account['fail_count'] = max(0, account.get('fail_count', 0) - 1)

        if account.get('priority', 1.0) < 1.0:
            account['priority'] = min(1.0, account.get('priority', 1.0) * 1.1)

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞
        total_checks = account.get('check_count', 1)
        fail_count = account.get('fail_count', 0)
        account['success_rate'] = 100 * (total_checks - fail_count) / total_checks

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏
        account['check_method'] = method

        # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —Å–Ω–∏–º–∞–µ–º —Ñ–ª–∞–≥ –∏ –Ω–µ —Å—á–∏—Ç–∞–µ–º —Ç–≤–∏—Ç –Ω–æ–≤—ã–º
        if first_check:
            account['first_check'] = False
            account['last_tweet_id'] = tweet_id
            logger.info(f"–ê–∫–∫–∞—É–Ω—Ç @{username}: –ø–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —Å–æ—Ö—Ä–∞–Ω–µ–Ω ID {tweet_id}")
            return True

        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –Ω–æ–≤—ã–π —Ç–≤–∏—Ç (ID –∏–∑–º–µ–Ω–∏–ª—Å—è)
        elif tweet_id != last_id:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª–µ–µ –Ω–æ–≤—ã–π —Ç–≤–∏—Ç –ø–æ ID
                is_newer = int(tweet_id) > int(last_id)
            except (ValueError, TypeError):
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å—Ä–∞–≤–Ω–∏—Ç—å –∫–∞–∫ —á–∏—Å–ª–∞, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –Ω–æ–≤—ã–π
                is_newer = True

            if is_newer:
                # –û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–æ–≤—ã–π —Ç–≤–∏—Ç!
                account['last_tweet_id'] = tweet_id
                logger.info(f"–ê–∫–∫–∞—É–Ω—Ç @{username}: –Ω–æ–≤—ã–π —Ç–≤–∏—Ç {tweet_id}, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è")

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤—Å–µ–º –ø–æ–¥–ø–∏—Å—á–∏–∫–∞–º
                if tweet_data:
                    tweet_text = tweet_data.get('text', '[–ù–æ–≤—ã–π —Ç–≤–∏—Ç]')
                    tweet_url = tweet_data.get('url', f"https://twitter.com/{username}/status/{tweet_id}")
                    tweet_msg = f"üê¶ @{username}:\n\n{tweet_text}\n\n{tweet_url}"

                    for chat_id in subs:
                        try:
                            await app.bot.send_message(chat_id=chat_id, text=tweet_msg,
                                                       disable_web_page_preview=False)
                            await asyncio.sleep(0.5)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∞—Ç {chat_id}: {e}")
                return True
            else:
                # ID –∏–∑–º–µ–Ω–∏–ª—Å—è, –Ω–æ —Ç–≤–∏—Ç —Å—Ç–∞—Ä–µ–µ - –ø—Ä–æ—Å—Ç–æ –æ–±–Ω–æ–≤–ª—è–µ–º ID
                account['last_tweet_id'] = tweet_id
                logger.info(f"–ê–∫–∫–∞—É–Ω—Ç @{username}: –æ–±–Ω–æ–≤–ª–µ–Ω ID —Ç–≤–∏—Ç–∞ –Ω–∞ {tweet_id}")
                return True
        else:
            logger.info(f"–ê–∫–∫–∞—É–Ω—Ç @{username}: –Ω–µ—Ç –Ω–æ–≤—ã—Ö —Ç–≤–∏—Ç–æ–≤ (–º–µ—Ç–æ–¥: {method})")
            return False

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞–∫–∫–∞—É–Ω—Ç–∞ @{username}: {e}")
        traceback.print_exc()

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –Ω–µ—É–¥–∞—á
        account['fail_count'] = account.get('fail_count', 0) + 1

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞
        total_checks = account.get('check_count', 1)
        fail_count = account.get('fail_count', 0)
        account['success_rate'] = 100 * (total_checks - fail_count) / total_checks

        # –£–º–µ–Ω—å—à–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤
        if account.get('fail_count', 0) > 3:
            account['priority'] = max(0.1, account.get('priority', 1.0) * 0.9)

        return True

# –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–æ—Ç –∫–æ–¥ –ø–µ—Ä–µ–¥ —Ñ—É–Ω–∫—Ü–∏–µ–π main()

async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    chat_id = update.effective_chat.id
    subs = load_json(SUBSCRIBERS_FILE, [])
    if chat_id not in subs:
        subs.append(chat_id)
        save_json(SUBSCRIBERS_FILE, subs)

    keyboard = InlineKeyboardMarkup([
        [InlineKeyboardButton("üìã –°–ø–∏—Å–æ–∫ –∞–∫–∫–∞—É–Ω—Ç–æ–≤", callback_data="list")],
        [InlineKeyboardButton("üîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–≤–∏—Ç—ã", callback_data="check")],
        [InlineKeyboardButton("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏", callback_data="settings")]
    ])

    await update.message.reply_text(
        "üëã –ë–æ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ Twitter!\n\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/add <username> - –¥–æ–±–∞–≤–∏—Ç—å –∞–∫–∫–∞—É–Ω—Ç\n"
        "/remove <username> - —É–¥–∞–ª–∏—Ç—å –∞–∫–∫–∞—É–Ω—Ç\n"
        "/list - —Å–ø–∏—Å–æ–∫ –∞–∫–∫–∞—É–Ω—Ç–æ–≤\n"
        "/check - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–≤–∏—Ç—ã\n"
        "/interval <–º–∏–Ω—É—Ç—ã> - –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏\n"
        "/settings - –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n"
        "/proxy - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∫—Å–∏\n"
        "/update_nitter - –æ–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤",
        reply_markup=keyboard
    )

async def cmd_add(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –∞–∫–∫–∞—É–Ω—Ç –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è"""
    if not context.args:
        return await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /add <username>")

    username = context.args[0].lstrip("@")
    accounts = init_accounts()

    if username.lower() in accounts:
        return await update.message.reply_text(f"@{username} —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω.")

    message = await update.message.reply_text(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º @{username}...")

    settings = get_settings()
    use_proxies = settings.get("use_proxies", False)
    methods = settings.get("scraper_methods", ["web", "nitter", "api"])

    user_id, tweet_id, tweet_data, method = await check_tweet_multi_method(
        username, methods, use_proxies
    )

    if not tweet_id:
        return await message.edit_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∞–∫–∫–∞—É–Ω—Ç @{username} –∏–ª–∏ –ø–æ–ª—É—á–∏—Ç—å –µ–≥–æ —Ç–≤–∏—Ç—ã.")

    accounts[username.lower()] = {
        "username": username,
        "user_id": user_id,
        "added_at": datetime.now().isoformat(),
        "last_check": datetime.now().isoformat(),
        "last_tweet_id": tweet_id,
        "check_count": 1,
        "success_rate": 100.0,
        "fail_count": 0,
        "check_method": method,
        "priority": 1.0,
        "first_check": True
    }
    save_accounts(accounts)

    tweet_text = tweet_data.get('text', '[–¢–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω]') if tweet_data else '[–¢–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω]'
    tweet_url = tweet_data.get('url', f"https://twitter.com/{username}/status/{tweet_id}") if tweet_data else f"https://twitter.com/{username}/status/{tweet_id}"

    result = f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω @{username}\n\nüìù –ü–æ—Å–ª–µ–¥–Ω–∏–π —Ç–≤–∏—Ç:\n{tweet_text}\n\nüÜî ID —Ç–≤–∏—Ç–∞: {tweet_id}\nüîç –ú–µ—Ç–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏: {method}\nüîó {tweet_url}\n\n–ë–æ—Ç –±—É–¥–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –Ω–æ–≤—ã–µ —Ç–≤–∏—Ç—ã —Å —ç—Ç–æ–≥–æ –º–æ–º–µ–Ω—Ç–∞."
    await message.edit_text(result)

async def cmd_remove(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–£–¥–∞–ª—è–µ—Ç –∞–∫–∫–∞—É–Ω—Ç –∏–∑ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è"""
    if not context.args:
        return await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /remove <username>")

    username = context.args[0].lstrip("@")
    accounts = init_accounts()

    if username.lower() not in accounts:
        return await update.message.reply_text(f"@{username} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–ø–∏—Å–∫–µ.")

    del accounts[username.lower()]
    save_accounts(accounts)
    await update.message.reply_text(f"‚úÖ –£–¥–∞–ª—ë–Ω @{username}.")

async def cmd_list(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤"""
    accounts = init_accounts()

    if not accounts:
        if hasattr(update, 'callback_query') and update.callback_query:
            return await update.callback_query.edit_message_text(
                "–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç. –î–æ–±–∞–≤—å—Ç–µ –∞–∫–∫–∞—É–Ω—Ç—ã —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /add <username>"
            )
        else:
            return await update.message.reply_text(
                "–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç. –î–æ–±–∞–≤—å—Ç–µ –∞–∫–∫–∞—É–Ω—Ç—ã —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /add <username>"
            )

    settings = get_settings()
    interval_mins = settings["check_interval"] // 60
    enabled = settings.get("enabled", True)
    status = "‚úÖ" if enabled else "‚ùå"

    msg = f"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏:\n‚Ä¢ –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏: {interval_mins} –º–∏–Ω.\n‚Ä¢ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: {status}\n\n"
    msg += f"üìã –ê–∫–∫–∞—É–Ω—Ç—ã ({len(accounts)}):\n"

    for username, data in sorted(accounts.items(), key=lambda x: x[1].get("priority", 1.0), reverse=True):
        display_name = data.get('username', username)
        last_check = data.get("last_check", "–Ω–∏–∫–æ–≥–¥–∞")
        tweet_id = data.get("last_tweet_id", "–Ω–µ—Ç")
        method = data.get("check_method", "unknown")
        success_rate = data.get("success_rate", 100.0)
        tweet_text = data.get("last_tweet_text", "")

        if last_check != "–Ω–∏–∫–æ–≥–¥–∞":
            try:
                check_dt = datetime.fromisoformat(last_check)
                last_check = check_dt.strftime("%Y-%m-%d %H:%M")
            except:
                last_check = "–Ω–µ–¥–∞–≤–Ω–æ"

        msg += f"‚Ä¢ @{display_name} (ID: {tweet_id}, {success_rate:.0f}%, –º–µ—Ç–æ–¥: {method}, –ø—Ä–æ–≤–µ—Ä–∫–∞: {last_check})"

        if tweet_text:
            short_text = tweet_text[:50] + "..." if len(tweet_text) > 50 else tweet_text
            msg += f"\n  ‚û°Ô∏è {short_text}"

        msg += "\n\n"

    keyboard = InlineKeyboardMarkup([
        [InlineKeyboardButton("üîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–≤–∏—Ç—ã", callback_data="check")],
        [InlineKeyboardButton("üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å", callback_data="check_force")],
        [InlineKeyboardButton("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏", callback_data="settings")]
    ])

    if hasattr(update, 'callback_query') and update.callback_query:
        await update.callback_query.edit_message_text(msg, reply_markup=keyboard)
    else:
        await update.message.reply_text(msg, reply_markup=keyboard)

async def cmd_check(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–æ–≤—ã–µ —Ç–≤–∏—Ç—ã"""
    force_update = False

    if context.args and (context.args[0].lower() in ['force', 'update', '–æ–±–Ω–æ–≤–∏—Ç—å']):
        force_update = True

    if hasattr(update, 'callback_query') and update.callback_query:
        if update.callback_query.data == "check_force":
            force_update = True
        message = await update.callback_query.edit_message_text(
            "–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–≤–∏—Ç—ã..." if force_update else "–ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–≤–∏—Ç—ã..."
        )
    else:
        message = await update.message.reply_text(
            "–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–≤–∏—Ç—ã..." if force_update else "–ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–≤–∏—Ç—ã..."
        )

    accounts = init_accounts()

    if not accounts:
        return await message.edit_text(
            "–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç. –î–æ–±–∞–≤—å—Ç–µ –∞–∫–∫–∞—É–Ω—Ç—ã —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /add <username>"
        )

    if not force_update:
        results = []

        for username, account in accounts.items():
            display_name = account.get('username', username)
            last_id = account.get('last_tweet_id')
            last_check = account.get('last_check', '–Ω–∏–∫–æ–≥–¥–∞')
            method = account.get('check_method', 'unknown')

            if last_check != '–Ω–∏–∫–æ–≥–¥–∞':
                try:
                    check_dt = datetime.fromisoformat(last_check)
                    last_check = check_dt.strftime("%Y-%m-%d %H:%M")
                except:
                    last_check = "–Ω–µ–¥–∞–≤–Ω–æ"

            if last_id:
                tweet_text = account.get('last_tweet_text', '[–¢–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω]')
                tweet_url = account.get('last_tweet_url', f"https://twitter.com/{display_name}/status/{last_id}")

                results.append(f"üì± @{display_name} (ID: {last_id}, –º–µ—Ç–æ–¥: {method}, –ø—Ä–æ–≤–µ—Ä–∫–∞: {last_check})\n" +
                               f"‚û°Ô∏è {tweet_text}\n‚û°Ô∏è {tweet_url}")
            else:
                results.append(f"‚ùì @{display_name}: —Ç–≤–∏—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        result_text = "üìä –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–≤–∏—Ç—ã:\n\n" + "\n\n".join(results)

        if len(result_text) > 4000:
            result_text = result_text[:3997] + "..."

        keyboard = InlineKeyboardMarkup([
            [InlineKeyboardButton("üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å", callback_data="check_force")],
            [InlineKeyboardButton("üìã –°–ø–∏—Å–æ–∫ –∞–∫–∫–∞—É–Ω—Ç–æ–≤", callback_data="list")]
        ])

        await message.edit_text(result_text, reply_markup=keyboard)
        return

    settings = get_settings()
    use_proxies = settings.get("use_proxies", False)
    methods = settings.get("scraper_methods", ["web", "nitter", "api"])

    results = []
    new_tweets = []
    found_tweets = []
    accounts_updated = False

    for username, account in accounts.items():
        display_name = account.get('username', username)
        last_id = account.get('last_tweet_id')
        first_check = account.get('first_check', False)

        account['last_check'] = datetime.now().isoformat()
        account['check_count'] = account.get('check_count', 0) + 1
        accounts_updated = True

        try:
            user_id, tweet_id, tweet_data, method = await check_tweet_multi_method(
                display_name, methods, use_proxies
            )

            if user_id and not account.get('user_id'):
                account['user_id'] = user_id
                accounts_updated = True

            if not tweet_id:
                account['fail_count'] = account.get('fail_count', 0) + 1
                total_checks = account.get('check_count', 1)
                fail_count = account.get('fail_count', 0)
                account['success_rate'] = 100 * (total_checks - fail_count) / total_checks

                if last_id:
                    results.append(f"‚ùì @{display_name}: —Ç–≤–∏—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø–æ—Å–ª–µ–¥–Ω–∏–π –∏–∑–≤–µ—Å—Ç–Ω—ã–π ID: {last_id}")
                else:
                    results.append(f"‚ùì @{display_name}: —Ç–≤–∏—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                continue

            if account.get('fail_count', 0) > 0:
                account['fail_count'] = max(0, account.get('fail_count', 0) - 1)

            total_checks = account.get('check_count', 1)
            fail_count = account.get('fail_count', 0)
            account['success_rate'] = 100 * (total_checks - fail_count) / total_checks

            account['check_method'] = method

            if tweet_data:
                found_tweets.append({
                    'username': display_name,
                    'tweet_id': tweet_id,
                    'data': tweet_data
                })

                tweet_text = tweet_data.get('text', '[–¢–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω]')
                tweet_url = tweet_data.get('url', f"https://twitter.com/{display_name}/status/{tweet_id}")
                account['last_tweet_text'] = tweet_text
                account['last_tweet_url'] = tweet_url

            if first_check:
                account['first_check'] = False
                account['last_tweet_id'] = tweet_id
                accounts_updated = True
                tweet_text = tweet_data.get('text', '[–¢–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω]') if tweet_data else '[–¢–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω]'
                tweet_url = tweet_data.get('url', f"https://twitter.com/{display_name}/status/{tweet_id}") if tweet_data else f"https://twitter.com/{display_name}/status/{tweet_id}"
                results.append(
                    f"üìù @{display_name}: –ø–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —Å–æ—Ö—Ä–∞–Ω–µ–Ω ID —Ç–≤–∏—Ç–∞ {tweet_id}\n‚û°Ô∏è –¢–µ–∫—Å—Ç: {tweet_text}\n‚û°Ô∏è –°—Å—ã–ª–∫–∞: {tweet_url}")
            elif tweet_id != last_id:
                try:
                    is_newer = int(tweet_id) > int(last_id)
                except (ValueError, TypeError):
                    is_newer = True

                if is_newer:
                    account['last_tweet_id'] = tweet_id
                    accounts_updated = True

                    tweet_text = tweet_data.get('text', '–¢–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω')
                    tweet_url = tweet_data.get('url', f"https://twitter.com/{display_name}/status/{tweet_id}")

                    new_tweet_msg = f"üî• –ù–æ–≤—ã–π —Ç–≤–∏—Ç –æ—Ç @{display_name}:\n\n{tweet_text}\n\nüîó {tweet_url}"
                    new_tweets.append(new_tweet_msg)
                    results.append(f"‚úÖ @{display_name}: –Ω–æ–≤—ã–π —Ç–≤–∏—Ç {tweet_id} (–º–µ—Ç–æ–¥: {method})")
                else:
                    account['last_tweet_id'] = tweet_id
                    accounts_updated = True
                    results.append(f"üîÑ @{display_name}: –æ–±–Ω–æ–≤–ª–µ–Ω ID —Ç–≤–∏—Ç–∞ –Ω–∞ {tweet_id} (–º–µ—Ç–æ–¥: {method})")
            else:
                results.append(f"üîÑ @{display_name}: –Ω–µ—Ç –Ω–æ–≤—ã—Ö —Ç–≤–∏—Ç–æ–≤ (–º–µ—Ç–æ–¥: {method})")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ @{display_name}: {e}")
            traceback.print_exc()
            results.append(f"‚ùå @{display_name}: –æ—à–∏–±–∫–∞ - {str(e)[:50]}")
            account['fail_count'] = account.get('fail_count', 0) + 1

    if accounts_updated:
        save_accounts(accounts)

    if new_tweets:
        await message.edit_text(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(new_tweets)} –Ω–æ–≤—ã—Ö —Ç–≤–∏—Ç–æ–≤!")

        for tweet_msg in new_tweets:
            await context.bot.send_message(chat_id=update.effective_chat.id, text=tweet_msg,
                                           disable_web_page_preview=False)
    else:
        result_text = "üîç –ù–æ–≤—ã—Ö —Ç–≤–∏—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.\n\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏:\n" + "\n".join(results)

        if len(result_text) > 4000:
            result_text = result_text[:3997] + "..."

        keyboard = InlineKeyboardMarkup([[
            InlineKeyboardButton("üîÑ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–Ω–æ–≤–∞", callback_data="check_force"),
            InlineKeyboardButton("üìã –°–ø–∏—Å–æ–∫ –∞–∫–∫–∞—É–Ω—Ç–æ–≤", callback_data="list")
        ]])

        await message.edit_text(result_text, reply_markup=keyboard)

async def cmd_interval(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    if not context.args:
        settings = get_settings()
        current_mins = settings["check_interval"] // 60
        return await update.message.reply_text(
            f"–¢–µ–∫—É—â–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏: {current_mins} –º–∏–Ω.\n"
            f"–î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è: /interval <–º–∏–Ω—É—Ç—ã>"
        )

    try:
        mins = int(context.args[0])
        if mins < 1:
            return await update.message.reply_text("–ò–Ω—Ç–µ—Ä–≤–∞–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ –º–µ–Ω–µ–µ 1 –º–∏–Ω—É—Ç—ã.")
        if mins > 1440:
            return await update.message.reply_text("–ò–Ω—Ç–µ—Ä–≤–∞–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ –±–æ–ª–µ–µ 1440 –º–∏–Ω—É—Ç (24 —á–∞—Å–∞).")

        settings = update_setting("check_interval", mins * 60)
        await update.message.reply_text(f"‚úÖ –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ {mins} –º–∏–Ω.")
    except ValueError:
        await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /interval <–º–∏–Ω—É—Ç—ã>")

async def cmd_settings(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞"""
    settings = get_settings()

    interval_mins = settings.get("check_interval", DEFAULT_CHECK_INTERVAL) // 60
    enabled = settings.get("enabled", True)
    use_proxies = settings.get("use_proxies", False)
    methods = settings.get("scraper_methods", ["web", "nitter", "api"])
    parallel_checks = settings.get("parallel_checks", 3)
    randomize = settings.get("randomize_intervals", True)

    enabled_status = "‚úÖ –≤–∫–ª—é—á–µ–Ω" if enabled else "‚ùå –≤—ã–∫–ª—é—á–µ–Ω"
    proxies_status = "‚úÖ –≤–∫–ª—é—á–µ–Ω–æ" if use_proxies else "‚ùå –≤—ã–∫–ª—é—á–µ–Ω–æ"
    randomize_status = "‚úÖ –≤–∫–ª—é—á–µ–Ω–æ" if randomize else "‚ùå –≤—ã–∫–ª—é—á–µ–Ω–æ"

    proxies = get_proxies()
    proxy_count = len(proxies.get("proxies", []))

    nitter_instances = settings.get("nitter_instances", [])
    nitter_count = len(nitter_instances)

    msg = (
        "‚öôÔ∏è **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞**\n\n"
        f"‚Ä¢ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: {enabled_status}\n"
        f"‚Ä¢ –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏: {interval_mins} –º–∏–Ω.\n"
        f"‚Ä¢ –°–ª—É—á–∞–π–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã: {randomize_status}\n"
        f"‚Ä¢ –û–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏: {parallel_checks}\n"
        f"‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∫—Å–∏: {proxies_status} (–¥–æ—Å—Ç—É–ø–Ω–æ: {proxy_count})\n"
        f"‚Ä¢ Nitter-–∏–Ω—Å—Ç–∞–Ω—Å—ã: {nitter_count}\n\n"
        f"‚Ä¢ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –º–µ—Ç–æ–¥–æ–≤: {', '.join(methods)}\n\n"
    )

    keyboard = []

    keyboard.append([
        InlineKeyboardButton("üîÑ –í–∫–ª/–≤—ã–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥", callback_data="toggle_monitoring"),
        InlineKeyboardButton("üîå –í–∫–ª/–≤—ã–∫–ª –ø—Ä–æ–∫—Å–∏", callback_data="toggle_proxies")
    ])

    keyboard.append([
        InlineKeyboardButton("API", callback_data="method_priority:api"),
        InlineKeyboardButton("Nitter", callback_data="method_priority:nitter"),
        InlineKeyboardButton("Web", callback_data="method_priority:web")
    ])

    keyboard.append([InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="list")])

    reply_markup = InlineKeyboardMarkup(keyboard)

    if hasattr(update, 'callback_query') and update.callback_query:
        await update.callback_query.edit_message_text(msg, reply_markup=reply_markup, parse_mode="Markdown")
    else:
        await update.message.reply_text(msg, reply_markup=reply_markup, parse_mode="Markdown")

async def cmd_proxy(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–∞–º–∏"""
    if not context.args:
        proxies = get_proxies()
        proxy_list = proxies.get("proxies", [])

        if not proxy_list:
            await update.message.reply_text(
                "‚ö†Ô∏è –°–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ –ø—É—Å—Ç.\n\n"
                "–î–æ–±–∞–≤—å—Ç–µ –ø—Ä–æ–∫—Å–∏ –∫–æ–º–∞–Ω–¥–æ–π:\n"
                "/proxy add <ip:port> –∏–ª–∏ <ip:port:user:pass>\n\n"
                "–î—Ä—É–≥–∏–µ –∫–æ–º–∞–Ω–¥—ã:\n"
                "/proxy list - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏\n"
                "/proxy clear - –æ—á–∏—Å—Ç–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏"
            )
            return

        msg = f"üîå –í—Å–µ–≥–æ –ø—Ä–æ–∫—Å–∏: {len(proxy_list)}\n\n"
        for i, proxy in enumerate(proxy_list[:20], 1):
            msg += f"{i}. `{proxy}`\n"

        if len(proxy_list) > 20:
            msg += f"\n... –∏ –µ—â–µ {len(proxy_list) - 20} –ø—Ä–æ–∫—Å–∏."

        msg += "\n\n–î–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n/proxy add <ip:port> –∏–ª–∏ <ip:port:user:pass>"

        await update.message.reply_text(msg, parse_mode="Markdown")
        return

    action = context.args[0].lower()

    if action == "add" and len(context.args) > 1:
        proxy = context.args[1]
        proxies = get_proxies()
        proxy_list = proxies.get("proxies", [])

        if ":" not in proxy:
            await update.message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–∫—Å–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ ip:port –∏–ª–∏ ip:port:user:pass")
            return

        if proxy not in proxy_list:
            proxy_list.append(proxy)
            proxies["proxies"] = proxy_list
            save_json(PROXIES_FILE, proxies)
            await update.message.reply_text(f"‚úÖ –ü—Ä–æ–∫—Å–∏ `{proxy}` –¥–æ–±–∞–≤–ª–µ–Ω. –í—Å–µ–≥–æ: {len(proxy_list)}",
                                            parse_mode="Markdown")
        else:
            await update.message.reply_text("‚ö†Ô∏è –≠—Ç–æ—Ç –ø—Ä–æ–∫—Å–∏ —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω")

    elif action == "list":
        proxies = get_proxies()
        proxy_list = proxies.get("proxies", [])

        if not proxy_list:
            await update.message.reply_text("–°–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ –ø—É—Å—Ç.")
            return

        msg = f"üîå –í—Å–µ–≥–æ –ø—Ä–æ–∫—Å–∏: {len(proxy_list)}\n\n"
        for i, proxy in enumerate(proxy_list[:20], 1):
            msg += f"{i}. `{proxy}`\n"

        if len(proxy_list) > 20:
            msg += f"\n... –∏ –µ—â–µ {len(proxy_list) - 20} –ø—Ä–æ–∫—Å–∏."

        await update.message.reply_text(msg, parse_mode="Markdown")

    elif action == "clear":
        save_json(PROXIES_FILE, {"proxies": []})
        await update.message.reply_text("‚úÖ –°–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ –æ—á–∏—â–µ–Ω")

    else:
        await update.message.reply_text(
            "‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n"
            "/proxy add <ip:port> - –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–∫—Å–∏\n"
            "/proxy list - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏\n"
            "/proxy clear - –æ—á–∏—Å—Ç–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏"
        )

async def cmd_update_nitter(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤"""
    message = await update.message.reply_text("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤...")

    try:
        instances = await update_nitter_instances()

        if instances:
            await message.edit_text(
                f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(instances)} —Ä–∞–±–æ—á–∏—Ö Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤:\n\n" +
                "\n".join(f"‚Ä¢ {instance}" for instance in instances)
            )
        else:
            await message.edit_text(
                "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö Nitter-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä—è–º–æ–π —Å–∫—Ä–∞–ø–∏–Ω–≥ Twitter."
            )
    except Exception as e:
        await message.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏: {str(e)}")

async def cmd_stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞"""
    accounts = init_accounts()

    if not accounts:
        return await update.message.reply_text("–ê–∫–∫–∞—É–Ω—Ç—ã –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã")

    total_checks = sum(acct.get("check_count", 0) for acct in accounts.values())
    total_fails = sum(acct.get("fail_count", 0) for acct in accounts.values())
    success_rate = 100.0 * (total_checks - total_fails) / max(1, total_checks)

    methods = {}
    for account in accounts.values():
        method = account.get("check_method")
        if method:
            methods[method] = methods.get(method, 0) + 1

    most_reliable = sorted(
        [(username, data.get("success_rate", 0)) for username, data in accounts.items()],
        key=lambda x: x[1],
        reverse=True
    )[:5]

    least_reliable = sorted(
        [(username, data.get("success_rate", 0)) for username, data in accounts.items()],
        key=lambda x: x[1]
    )[:5]

    msg = (
        "üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞**\n\n"
        f"‚Ä¢ –í—Å–µ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {len(accounts)}\n"
        f"‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–æ–∫: {total_checks}\n"
        f"‚Ä¢ –£—Å–ø–µ—à–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫: {total_checks - total_fails} ({success_rate:.1f}%)\n\n"

        "**–ú–µ—Ç–æ–¥—ã –ø—Ä–æ–≤–µ—Ä–∫–∏:**\n"
    )

    for method, count in methods.items():
        percent = 100.0 * count / len(accounts)
        msg += f"‚Ä¢ {method}: {count} ({percent:.1f}%)\n"

    msg += "\n**–°–∞–º—ã–µ –Ω–∞–¥–µ–∂–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã:**\n"
    for username, rate in most_reliable:
        msg += f"‚Ä¢ @{accounts[username].get('username', username)}: {rate:.1f}%\n"

    msg += "\n**–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã:**\n"
    for username, rate in least_reliable:
        msg += f"‚Ä¢ @{accounts[username].get('username', username)}: {rate:.1f}%\n"

    await update.message.reply_text(msg, parse_mode="Markdown")

async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–∂–∞—Ç–∏–π –Ω–∞ –∫–Ω–æ–ø–∫–∏"""
    query = update.callback_query
    await query.answer()

    if query.data == "list":
        await cmd_list(update, context)
    elif query.data == "check":
        await cmd_check(update, context)
    elif query.data == "settings":
        await cmd_settings(update, context)
    elif query.data == "toggle_proxies":
        await toggle_proxies(update, context)
    elif query.data == "toggle_monitoring":
        await toggle_monitoring(update, context)
    elif query.data.startswith("method_priority:"):
        method = query.data.split(":", 1)[1]
        await change_method_priority(update, context, method)

async def toggle_proxies(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–í–∫–ª—é—á–∞–µ—Ç/–≤—ã–∫–ª—é—á–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∫—Å–∏"""
    settings = get_settings()
    current = settings.get("use_proxies", False)
    settings["use_proxies"] = not current
    save_json(SETTINGS_FILE, settings)

    status = "‚úÖ –≤–∫–ª—é—á–µ–Ω–æ" if settings["use_proxies"] else "‚ùå –≤—ã–∫–ª—é—á–µ–Ω–æ"
    proxies = get_proxies()
    proxy_count = len(proxies.get("proxies", []))

    await update.callback_query.edit_message_text(
        f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∫—Å–∏: {status}\n\n"
        f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∫—Å–∏: {proxy_count}\n\n"
        "–í–µ—Ä–Ω–∏—Ç–µ—Å—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å –ø–æ–º–æ—â—å—é /settings",
    )

async def toggle_monitoring(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–í–∫–ª—é—á–∞–µ—Ç/–≤—ã–∫–ª—é—á–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
    settings = get_settings()
    current = settings.get("enabled", True)
    settings["enabled"] = not current
    save_json(SETTINGS_FILE, settings)

    status = "‚úÖ –≤–∫–ª—é—á–µ–Ω" if settings["enabled"] else "‚ùå –≤—ã–∫–ª—é—á–µ–Ω"

    await update.callback_query.edit_message_text(
        f"–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: {status}\n\n"
        "–í–µ—Ä–Ω–∏—Ç–µ—Å—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å –ø–æ–º–æ—â—å—é /settings",
    )

async def change_method_priority(update: Update, context: ContextTypes.DEFAULT_TYPE, method):
    """–ò–∑–º–µ–Ω—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –º–µ—Ç–æ–¥–æ–≤ –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    settings = get_settings()
    methods = settings.get("scraper_methods", ["web", "nitter", "api"])

    if method in methods:
        methods.remove(method)
    methods.insert(0, method)

    settings["scraper_methods"] = methods
    save_json(SETTINGS_FILE, settings)

    await cmd_settings(update, context)

def main():
    if not TG_TOKEN:
        logger.error("TG_TOKEN –Ω–µ —É–∫–∞–∑–∞–Ω –≤ .env —Ñ–∞–π–ª–µ")
        return

    for path, default in [
        (SUBSCRIBERS_FILE, []),
        (SETTINGS_FILE, {
            "check_interval": DEFAULT_CHECK_INTERVAL,
            "enabled": True,
            "use_proxies": False,
            "scraper_methods": ["api", "apify", "web", "nitter"] if APIFY_API_TOKEN else ["api", "web", "nitter"],
            "max_retries": 3,
            "cache_expiry": 3600,
            "randomize_intervals": True,
            "min_interval_factor": 0.8,
            "max_interval_factor": 1.2,
            "parallel_checks": 3,
            "nitter_instances": NITTER_INSTANCES
        })
    ]:
        if not os.path.exists(path):
            save_json(path, default)

    app = ApplicationBuilder().token(TG_TOKEN).post_init(on_startup).post_shutdown(on_shutdown).build()

    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("add", cmd_add))
    app.add_handler(CommandHandler("remove", cmd_remove))
    app.add_handler(CommandHandler("list", cmd_list))
    app.add_handler(CommandHandler("check", cmd_check))
    app.add_handler(CommandHandler("interval", cmd_interval))
    app.add_handler(CommandHandler("settings", cmd_settings))
    app.add_handler(CommandHandler("proxy", cmd_proxy))
    app.add_handler(CommandHandler("stats", cmd_stats))
    app.add_handler(CommandHandler("update_nitter", cmd_update_nitter))

    app.add_handler(CallbackQueryHandler(button_handler))

    settings = get_settings()
    interval_mins = settings["check_interval"] // 60
    logger.info(f"üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω, –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏: {interval_mins} –º–∏–Ω.")
    app.run_polling()


if __name__ == "__main__":
    main()